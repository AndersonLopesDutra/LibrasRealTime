# ğŸ‡§ğŸ‡· LibrasRealTime

## ğŸš€ VisÃ£o Geral do Projeto

O `LibrasRealTime` Ã© um projeto de VisÃ£o Computacional em tempo real que visa explorar e aplicar tÃ©cnicas de Machine Learning e Deep Learning para a detecÃ§Ã£o de gestos e caracterÃ­sticas faciais. Desenvolvido em Python, utiliza as capacidades de processamento de imagem de bibliotecas lÃ­deres da indÃºstria para interagir com a cÃ¢mera do notebook.

**Objetivos principais:**
* Detectar e mapear pontos-chave (landmarks) de mÃ£os para reconhecimento de gestos (foco inicial no alfabeto LIBRAS).
* Realizar detecÃ§Ã£o e mapeamento facial, demonstrando conceitos de biometria e anÃ¡lise estrutural do rosto.
* Servir como plataforma de estudo e prÃ¡tica em CiÃªncia de Dados, VisÃ£o Computacional e Machine Learning.

## âš™ï¸ Tecnologias e Ferramentas

Este projeto foi construÃ­do utilizando as seguintes tecnologias e bibliotecas:

* **Linguagem:** Python ğŸ
* **VisÃ£o Computacional:** OpenCV (Open Source Computer Vision Library)
    * Utilizado para acesso Ã  cÃ¢mera, manipulaÃ§Ã£o de imagens (conversÃ£o de cores, desenho, exibiÃ§Ã£o).
* **Deep Learning/Modelos PrÃ©-Treinados:** MediaPipe (Google)
    * Fornece modelos otimizados para detecÃ§Ã£o de mÃ£os (`Hands`) e malha facial (`FaceMesh`), extraindo landmarks em tempo real.
* **Processamento NumÃ©rico:** NumPy
    * Base para manipulaÃ§Ã£o eficiente de dados numÃ©ricos e arrays.
* **ComputaÃ§Ã£o CientÃ­fica:** SciPy
    * Biblioteca de algoritmos e funÃ§Ãµes para computaÃ§Ã£o cientÃ­fica, utilizada em algumas abordagens de malha geomÃ©trica.
* **Ambiente de Desenvolvimento Integrado (IDE):** PyCharm
* **Controle de VersÃ£o:** Git
* **Hospedagem de RepositÃ³rio:** GitHub

## âœ¨ Funcionalidades Atuais

O projeto `LibrasRealTime` atualmente oferece os seguintes mÃ³dulos e funcionalidades:

### ğŸ–ï¸ DetecÃ§Ã£o de MÃ£os (MÃ³dulo `hand_tracker.py`)
* Acesso em tempo real Ã  cÃ¢mera do notebook.
* DetecÃ§Ã£o precisa de uma ou mais mÃ£os utilizando o modelo `MediaPipe Hands`.
* Mapeamento e visualizaÃ§Ã£o dos 21 pontos-chave (landmarks) de cada mÃ£o.
* ExibiÃ§Ã£o do FPS (Frames Per Second) para monitoramento de performance.
* **PropÃ³sito:** Base para o futuro reconhecimento do alfabeto em LIBRAS.

### ğŸ‘¤ DetecÃ§Ã£o e Mapeamento Facial (MÃ³dulo `face_mesh_tracker.py`)
* Acesso em tempo real Ã  cÃ¢mera do notebook.
* DetecÃ§Ã£o detalhada da malha facial utilizando o modelo `MediaPipe FaceMesh`.
* ExtraÃ§Ã£o de mais de 400 pontos-chave do rosto.
* RenderizaÃ§Ã£o de uma malha customizada e minimalista sobre o rosto (inspirada em biometria facial).
* ExibiÃ§Ã£o do FPS para monitoramento de performance.
* **PropÃ³sito:** Estudo e demonstraÃ§Ã£o de conceitos de biometria e anÃ¡lise estrutural da face.

## ğŸš€ Como Executar o Projeto

Para configurar e executar o projeto em seu ambiente local, siga os passos abaixo:

### ğŸ“‹ PrÃ©-requisitos
* Python 3.11 (recomendado para compatibilidade com MediaPipe)
* Git (instalado e configurado)
* PyCharm (ou sua IDE Python preferida)

### â¬‡ï¸ 1. Clonar o RepositÃ³rio

Abra seu terminal e execute o comando:
```bash
git clone [https://github.com/AndersonLopesDutra/LibrasRealTime.git](https://github.com/AndersonLopesDutra/LibrasRealTime.git)

Em seguida, navegue atÃ© a pasta do projeto:

Bash

cd LibrasRealTime
ğŸ 2. Configurar o Ambiente Virtual
Ã‰ altamente recomendado usar um ambiente virtual para isolar as dependÃªncias do projeto.

No PyCharm:
Abra a pasta do projeto (File -> Open...).

VÃ¡ em File -> Settings... -> Project: LibrasRealTime -> Python Interpreter.

Clique em Add Interpreter -> Add Local Interpreter....

Selecione Virtualenv Environment e New environment.

Garanta que o Base interpreter seja o Python 3.11 que vocÃª instalou.

Clique em OK para criar o ambiente.

ğŸ“¦ 3. Instalar as DependÃªncias
Com o ambiente virtual ativado no terminal do PyCharm (vocÃª verÃ¡ (.venv) no prompt), instale todas as bibliotecas necessÃ¡rias com um Ãºnico comando:

Bash

pip install -r requirements.txt
â–¶ï¸ 4. Executar os MÃ³dulos
ApÃ³s a instalaÃ§Ã£o das dependÃªncias, vocÃª pode executar os mÃ³dulos de detecÃ§Ã£o:

Para DetecÃ§Ã£o de MÃ£os:
Bash

python main.py
Para DetecÃ§Ã£o Facial:
Bash

python main_face.py
Pressione ESC em qualquer uma das janelas para encerrar a execuÃ§Ã£o.

ğŸ¯ PrÃ³ximos Passos (Roadmap Futuro)
ImplementaÃ§Ã£o do Reconhecimento do Alfabeto LIBRAS: Treinamento de um modelo de Machine Learning (classificador) utilizando os landmarks das mÃ£os para identificar as letras do alfabeto estÃ¡tico em LIBRAS.

DetecÃ§Ã£o de Objeto Customizada: Treinar um modelo de Deep Learning (e.g., YOLO) para detectar objetos especÃ­ficos (como um cigarro) e verificar a interaÃ§Ã£o com as feiÃ§Ãµes faciais.

Aprimoramento da Interface: Melhorias na visualizaÃ§Ã£o e na interaÃ§Ã£o com o usuÃ¡rio.

